# -*- coding: utf-8 -*-
"""bmw_tech_interview_prep

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DJCyr42RRV1F7iLhjHv4Fmdhag0ZhqXx

"""
"""#   0 Check and install libraries"""
import os
import matplotlib.pyplot as plt
import transformers
import torch
import tiktoken

from pathlib import Path
import pandas as pd


from src.bmw_functions import evaluation, evaluate_multi_choice, load_text_files, sample_text, train
from src.data_loader import DataLoaderLite
from src.gpt_model import GPT


print(f"transformers version: {transformers.__version__}")
print(f"torch version: {torch.__version__}")

# attempt to autodetect the device
device = "cpu"
if torch.cuda.is_available():
    device = "cuda"
elif hasattr(torch.backends, "mps") and torch.backends.mps.is_available():
    device = "mps"
print(f"using device: {device}")

SAMPLE_PROMPT = "BWM Germany today"
NUM_RETURN_SEQUENCES = 2
MAX_LENGTH = 300


def build_sample_tokens(prompt: str, num_return_sequences: int):
    enc = tiktoken.get_encoding("gpt2")
    tokens = enc.encode(prompt)
    tokens = torch.tensor(tokens, dtype=torch.long)
    tokens = tokens.unsqueeze(0).repeat(num_return_sequences, 1)
    return enc, tokens


def run_validation(model, valid_text, device, label):
    valid_loader = DataLoaderLite(B=8, T=64, text=valid_text)
    loss = evaluation(model, valid_loader, device)
    print(f"\nThe average validation loss {label}: {loss}")
    return loss

"""#1 Prepare data"""

"""## 1.1 Load dataset from google drive"""
texts = load_text_files(Path("./data/bmw_news"), 1)

"""## 1.2 Create train and valid datasets"""
train_data_percentage = 0.8
train_data_file_number = int(len(texts) * train_data_percentage)
train_strings = texts[:train_data_file_number]
valid_strings = texts[train_data_file_number:]
train_text = "\n".join(train_strings)
valid_text = "\n".join(valid_strings)
print('='*80)
print(f"There are {train_data_file_number} files included in training data and {sum(len(text) for text in train_strings)} characters")
print("Training data sample")
print('='*80)
print(print(train_text[:300]))
print()
print('='*80)
print(f"There are {len(texts)-train_data_file_number} files included in validation data and {sum(len(text) for text in valid_strings)} characters")
print("Validation data sample")
print('='*80)
print(print(valid_text[:300]))

"""## 1.3 Load 100 BMW multi choice Q&A"""
df= pd.read_csv('./data/bmw_multi_choice/data.csv')
bmw_multi_choice_data = df.to_dict(orient="records")
bmw_multi_choice_data[10]


"""# 2 Finetuning a Model on BMW Press Releases"""
"""## 2.1 Define the model (GPT2)"""
"""## 2.2 Define data loader"""

"""## 2.3 Create model and initialize the weights from GPT2 from HuggingFace"""
# load open weights gpt2 model from https://huggingface.co/openai-community/gpt2
# n_layer=12, n_head=12, n_embd=768, 124M params
model = GPT.from_pretrained('gpt2')
model.to(device)

"""## 2.4 Evaluation on validation data before fine tuning"""
loss_main_before = run_validation(model, valid_text, device, "before fine tuning")

"""##2.5 Sample text generation before fine tuning"""

# sample text generation
enc, sample_tokens = build_sample_tokens(SAMPLE_PROMPT, NUM_RETURN_SEQUENCES)
sample_text(model, NUM_RETURN_SEQUENCES, MAX_LENGTH, enc, sample_tokens, device)

"""## 2.6 BMW news Q&A evaluation before fine tuning"""

acc_main_before = evaluate_multi_choice(model, device, bmw_multi_choice_data)

"""## 2.7 Model fine tuning"""

train_loader = DataLoaderLite(B=8, T=64, text=train_text)
model, epoch_loss_main = train(train_loader, model, 5, device)

"""## 2.8 Evaluation on validation data after fine tuning"""
loss_main_after = run_validation(model, valid_text, device, "after fine tuning")

"""##2.9 Sample text generation after fine tuning"""

# sample text generation
sample_text(model, NUM_RETURN_SEQUENCES, MAX_LENGTH, enc, sample_tokens, device)

"""## 2.10 BMW news Q&A evaluation after fine tuning"""

acc_main_after = evaluate_multi_choice(model, device, bmw_multi_choice_data)

"""# 3: Stretch version

## 3.1 Create model and initialize the weights from GPT2 from HuggingFace
"""

import torch.nn as nn

# load open weights gpt2 model from https://huggingface.co/openai-community/gpt2
# n_layer=12, n_head=12, n_embd=768, 124M params
model_reduced= GPT.from_pretrained('gpt2')

"""## 3.2 Remove the last transformer block from the GPT2 model"""

# Remove last block
model_reduced.transformer.h = nn.ModuleList(model_reduced.transformer.h[:-1])

# Update config
model_reduced.config.n_layer -= 1
model_reduced.to(device)

"""## 3.3 Evaluation on validation data before fine tuning"""
loss_reduced_before = run_validation(model_reduced, valid_text, device, "before fine tuning")

"""## 3.4 Sample text generation before fine tuning"""

# sample text generation
sample_text(model_reduced, NUM_RETURN_SEQUENCES, MAX_LENGTH, enc, sample_tokens, device)

"""## 3.5 BMW news Q&A evaluation before fine tuning"""

acc_reduced_before = evaluate_multi_choice(model_reduced, device, bmw_multi_choice_data)

"""## 3.6 Reduced model fine training"""

train_loader = DataLoaderLite(B=8, T=64, text=train_text)
model_reduced, epoch_loss_reduced = train(train_loader, model_reduced, 5, device)

"""## 3.7 Evaluation on validation data after fine tuning"""
loss_reduced_after = run_validation(model_reduced, valid_text, device, "after fine tuning")

"""##3.8 Sample text generation after fine tuning"""

# sample text generation
sample_text(model_reduced, NUM_RETURN_SEQUENCES, MAX_LENGTH, enc, sample_tokens, device)

"""## 3.9 BMW news Q&A evaluation after fine tuning"""

acc_reduced_after = evaluate_multi_choice(model_reduced, device, bmw_multi_choice_data)

plt.figure(figsize=(8, 5))
plt.plot(epoch_loss_main, label="GPT2")
plt.plot(epoch_loss_reduced, label="GPT2 (reduced)")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.legend()
plt.tight_layout()
plt.savefig("training_loss_comparison.png", dpi=150)
plt.show()

scenario_labels = [
    "GPT2 before",
    "GPT2 after",
    "GPT2 reduced before",
    "GPT2 reduced after",
]
loss_values = [
    loss_main_before,
    loss_main_after,
    loss_reduced_before,
    loss_reduced_after,
]
acc_values = [
    acc_main_before,
    acc_main_after,
    acc_reduced_before,
    acc_reduced_after,
]

plt.figure(figsize=(9, 5))
plt.bar(scenario_labels, loss_values, color=["#1f77b4", "#1f77b4", "#ff7f0e", "#ff7f0e"])
plt.ylabel("Validation Loss")
plt.title("Validation Loss by Scenario")
plt.xticks(rotation=20, ha="right")
plt.tight_layout()
plt.savefig("validation_loss_comparison.png", dpi=150)
plt.show()

plt.figure(figsize=(9, 5))
plt.bar(scenario_labels, acc_values, color=["#1f77b4", "#1f77b4", "#ff7f0e", "#ff7f0e"])
plt.ylabel("Accuracy")
plt.title("Validation Accuracy by Scenario")
plt.xticks(rotation=20, ha="right")
plt.tight_layout()
plt.savefig("validation_accuracy_comparison.png", dpi=150)
plt.show()