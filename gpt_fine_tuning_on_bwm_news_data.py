# -*- coding: utf-8 -*-
"""bmw_tech_interview_prep

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DJCyr42RRV1F7iLhjHv4Fmdhag0ZhqXx

"""
"""#   0 Check and install libraries"""
import logging
import os

import transformers
import torch
import tiktoken

from pathlib import Path
import pandas as pd
import torch.nn as nn

from src.bmw_functions import evaluation, evaluate_multi_choice, load_text_files, sample_text, train
from src.data_loader import DataLoaderLite
from src.gpt_model import GPT
from src.visualization import plot_training_loss, plot_validation_metrics


logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)s | %(message)s",
)
logger = logging.getLogger(__name__)


logger.info("transformers version: %s", transformers.__version__)
logger.info("torch version: %s", torch.__version__)

# attempt to autodetect the device
device = "cpu"
if torch.cuda.is_available():
    device = "cuda"
elif hasattr(torch.backends, "mps") and torch.backends.mps.is_available():
    device = "mps"
logger.info("using device: %s", device)

SAMPLE_PROMPT = "BWM Germany today"
NUM_RETURN_SEQUENCES = 2
MAX_LENGTH = 300


def build_sample_tokens(prompt: str, num_return_sequences: int):
    enc = tiktoken.get_encoding("gpt2")
    tokens = enc.encode(prompt)
    tokens = torch.tensor(tokens, dtype=torch.long)
    tokens = tokens.unsqueeze(0).repeat(num_return_sequences, 1)
    return enc, tokens


def run_validation(model, valid_text, device, label):
    valid_loader = DataLoaderLite(B=8, T=64, text=valid_text)
    loss = evaluation(model, valid_loader, device)
    logger.info("validation loss %s: %.6f", label, loss)
    return loss

"""#1 Prepare data"""

"""## 1.1 Load dataset from google drive"""
texts = load_text_files(Path("./data/bmw_news"), 1)

"""## 1.2 Create train and valid datasets"""
train_data_percentage = 0.8
train_data_file_number = int(len(texts) * train_data_percentage)
train_strings = texts[:train_data_file_number]
valid_strings = texts[train_data_file_number:]
train_text = "\n".join(train_strings)
valid_text = "\n".join(valid_strings)
train_chars = sum(len(text) for text in train_strings)
valid_chars = sum(len(text) for text in valid_strings)
logger.info(
    "training data: %s files, %s characters",
    train_data_file_number,
    train_chars,
)
logger.info("training data sample:\n%s", train_text[:300])
logger.info(
    "validation data: %s files, %s characters",
    len(texts) - train_data_file_number,
    valid_chars,
)
logger.info("validation data sample:\n%s", valid_text[:300])

"""## 1.3 Load 100 BMW multi choice Q&A"""
df= pd.read_csv('./data/bmw_multi_choice/data.csv')
bmw_multi_choice_data = df.to_dict(orient="records")
bmw_multi_choice_data[10]


"""# 2 Finetuning a Model on BMW Press Releases"""
"""## 2.1 Define the model (GPT2)"""
"""## 2.2 Define data loader"""

"""## 2.3 Create model and initialize the weights from GPT2 from HuggingFace"""
# load open weights gpt2 model from https://huggingface.co/openai-community/gpt2
# n_layer=12, n_head=12, n_embd=768, 124M params
model = GPT.from_pretrained('gpt2')
model.to(device)

"""## 2.4 Evaluation on validation data before fine tuning"""
loss_main_before = run_validation(model, valid_text, device, "before fine tuning")

"""##2.5 Sample text generation before fine tuning"""

# sample text generation
enc, sample_tokens = build_sample_tokens(SAMPLE_PROMPT, NUM_RETURN_SEQUENCES)
sample_text(model, NUM_RETURN_SEQUENCES, MAX_LENGTH, enc, sample_tokens, device)

"""## 2.6 BMW news Q&A evaluation before fine tuning"""

acc_main_before = evaluate_multi_choice(model, device, bmw_multi_choice_data)

"""## 2.7 Model fine tuning"""

train_loader = DataLoaderLite(B=8, T=64, text=train_text)
model, epoch_loss_main = train(train_loader, model, 5, device)

"""## 2.8 Evaluation on validation data after fine tuning"""
loss_main_after = run_validation(model, valid_text, device, "after fine tuning")

"""##2.9 Sample text generation after fine tuning"""

# sample text generation
sample_text(model, NUM_RETURN_SEQUENCES, MAX_LENGTH, enc, sample_tokens, device)

"""## 2.10 BMW news Q&A evaluation after fine tuning"""

acc_main_after = evaluate_multi_choice(model, device, bmw_multi_choice_data)

"""# 3: Stretch version

## 3.1 Create model and initialize the weights from GPT2 from HuggingFace
"""



# load open weights gpt2 model from https://huggingface.co/openai-community/gpt2
# n_layer=12, n_head=12, n_embd=768, 124M params
model_reduced= GPT.from_pretrained('gpt2')

"""## 3.2 Remove the last transformer block from the GPT2 model"""

# Remove last block
model_reduced.transformer.h = nn.ModuleList(model_reduced.transformer.h[:-1])

# Update config
model_reduced.config.n_layer -= 1
model_reduced.to(device)

"""## 3.3 Evaluation on validation data before fine tuning"""
loss_reduced_before = run_validation(model_reduced, valid_text, device, "before fine tuning")

"""## 3.4 Sample text generation before fine tuning"""

# sample text generation
sample_text(model_reduced, NUM_RETURN_SEQUENCES, MAX_LENGTH, enc, sample_tokens, device)

"""## 3.5 BMW news Q&A evaluation before fine tuning"""

acc_reduced_before = evaluate_multi_choice(model_reduced, device, bmw_multi_choice_data)

"""## 3.6 Reduced model fine training"""

train_loader = DataLoaderLite(B=8, T=64, text=train_text)
model_reduced, epoch_loss_reduced = train(train_loader, model_reduced, 5, device)

"""## 3.7 Evaluation on validation data after fine tuning"""
loss_reduced_after = run_validation(model_reduced, valid_text, device, "after fine tuning")

"""##3.8 Sample text generation after fine tuning"""

# sample text generation
sample_text(model_reduced, NUM_RETURN_SEQUENCES, MAX_LENGTH, enc, sample_tokens, device)

"""## 3.9 BMW news Q&A evaluation after fine tuning"""

acc_reduced_after = evaluate_multi_choice(model_reduced, device, bmw_multi_choice_data)

"""# 4 Plot training loss and validation metrics"""
scenario_labels = [
    "GPT2 before",
    "GPT2 after",
    "GPT2 reduced before",
    "GPT2 reduced after",
]
loss_values = [
    loss_main_before,
    loss_main_after,
    loss_reduced_before,
    loss_reduced_after,
]
acc_values = [
    acc_main_before,
    acc_main_after,
    acc_reduced_before,
    acc_reduced_after,
]

plot_training_loss(epoch_loss_main, epoch_loss_reduced)
plot_validation_metrics(scenario_labels, loss_values, acc_values)